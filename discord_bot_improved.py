import discord
from discord.ext import commands, tasks
import os
import emoji
import re
import asyncio
import datetime
from dotenv import load_dotenv
import unicodedata
from aiohttp import web

intents = discord.Intents.default()
intents.message_content = True
intents.members = True
intents.messages = True

bot = commands.Bot(command_prefix='$', intents=intents)

# === SETTINGS ===

BYPASS_ROLES = [1453188702984601673, 1453188706541240330, 1453188775973884126]
LOG_CHANNEL_ID = 1453066942532554802

MONITORED_CHANNELS = [
    1453067297743704217,
    1453067980878512290
]

BLOCKED_MESSAGES = [
    "https://raw.githubusercontent.com/ayawtandogaakongotin/buangka",
    "üÑ∑üÖÉüÖÉüÑøüÖÇ",
    "üÖÉüÑ¥üÑªüÑ¥",
    "ayawtandogaakongotin",
    "jxbadscript",
    "raw.githubusercontent.com",
    "SKIDDER"
]

BLOCKED_WORDS = [
    "crack", "cracked", "copypaster", "paster", "ghost", "niga", "skid", "skidded", 
    "skidder", "skidding", "script kiddie", "scriptkiddie", "sk1d", "sk!d", "sk!dded",
    "skidd", "skido"
]

WHITELIST_WORDS = [
    "recoil", "external", "solara", "solar", "recollect", "recover", "record", "recommend",
    "skeleton", "skilled", "skiing", "skincare", "asking", "risking", "whisker", "brisket",
    "basket", "casket", "gasket", "masked", "asked", "tasked", "flask", "mask",
    "fantastic", "astic", "drastic", "plastic", "elastic", "classic", "jurassic",
    "ghost writer", "ghosting", "ghostly", "ghosted", "past", "paste", "pasted"
]

# Allowed domains (whitelist)
ALLOWED_DOMAINS = [
    "discord.com",
    "discord.gg",
    "discordapp.com",
    "getjx.vercel.app",
    "tenor.com",
    "giphy.com",
    "imgur.com",
    "youtube.com",
    "youtu.be",
    "twitter.com",
    "x.com",
    "github.com",
    "githubusercontent.com"  # Only if not in blocked messages
]

# === AUTO-REPLY PATTERNS ===

AUTO_REPLY_PATTERNS = {
    r'(?i)(?:does|do|is)\s+(?:melee\s+)?(?:reach|aura)\s+(?:work|working)\s*(?:with|on)?\s*(?:fire\s+axe|axe)?': {
        'response': "Yes, it's working! üî•",
        'description': 'Melee reach/aura functionality'
    },
    r'(?i)(?:where|how)\s+(?:is|to\s+get|can\s+i\s+get|do\s+i\s+get)\s+(?:the\s+)?script': {
        'response': "You can get/copy the script at this link: https://getjx.vercel.app/ üìú",
        'description': 'Script download location'
    },
    r'(?i)(?:wheres?|where\s+is)\s+(?:the\s+)?script': {
        'response': "You can get/copy the script at this link: https://getjx.vercel.app/ üìú",
        'description': 'Script location'
    },
    r'(?i)(?:where|how)\s+(?:to\s+get|can\s+i\s+get|do\s+i\s+get)\s+(?:a\s+)?key': {
        'response': "Please read https://discord.com/channels/1350403770986528779/1390636325752934430 to get your key, or you can buy a premium key at https://discord.com/channels/1350403770986528779/1423933307137163274 üîë",
        'description': 'Key acquisition guide'
    },
    r'(?i)(?:where|how)\s+(?:to\s+buy|can\s+i\s+buy)\s+(?:premium\s+)?key': {
        'response': "You can buy a premium key at https://discord.com/channels/1350403770986528779/1423933307137163274 üíé",
        'description': 'Premium key purchase'
    },
    r'(?i)why\s+(?:is\s+)?my\s+key\s+(?:not\s+working|broken|invalid)': {
        'response': "Try turning off your VPN and make sure you're using the correct key format. If the issue persists, please contact support! üõ†Ô∏è",
        'description': 'Key troubleshooting'
    },
    r'(?i)(?:how\s+to\s+get|where\s+to\s+find|need)\s+(?:the\s+)?script': {
        'response': "You can get/copy the script at this link: https://getjx.vercel.app/ üìú",
        'description': 'Script access'
    }
}

# === ENHANCED LINK DETECTION ===

def detect_links(text):
    """Enhanced link detection with multiple methods"""
    if not text:
        return False, []
    
    violations = []
    found_links = []
    
    # Convert Unicode to ASCII first
    converted_text = comprehensive_unicode_to_ascii(text).lower()
    original_lower = text.lower()
    
    # Method 1: Standard URL patterns
    url_patterns = [
        r'https?://[^\s]+',
        r'www\.[^\s]+',
        r'[a-zA-Z0-9-]+\.[a-zA-Z]{2,}(?:/[^\s]*)?',
    ]
    
    for pattern in url_patterns:
        matches = re.findall(pattern, converted_text)
        found_links.extend(matches)
        matches = re.findall(pattern, original_lower)
        found_links.extend(matches)
    
    # Method 2: Detect obfuscated URLs
    obfuscated_patterns = [
        r'h\s*t\s*t\s*p\s*s?\s*:\s*//\s*[^\s]+',
        r'h\s*t\s*t\s*p\s*[s:]?\s*[:/]+\s*[^\s]+',
        r'w\s*w\s*w\s*\.\s*[^\s]+',
    ]
    
    for pattern in obfuscated_patterns:
        matches = re.findall(pattern, converted_text, re.IGNORECASE)
        if matches:
            found_links.extend(matches)
            violations.append("Obfuscated link detected")
    
    # Method 3: Detect domain-like patterns
    domain_pattern = r'\b[a-zA-Z0-9-]+\.(?:com|net|org|io|gg|xyz|info|co|me|tv|cc|vip|pro|online|site|tech|store|app|dev|link|club|fun|top|best|win|life|world)\b'
    domain_matches = re.findall(domain_pattern, converted_text, re.IGNORECASE)
    found_links.extend(domain_matches)
    
    # Method 4: Detect URL shorteners
    shortener_pattern = r'\b(?:bit\.ly|tinyurl|goo\.gl|ow\.ly|t\.co|buff\.ly|adf\.ly|is\.gd|tr\.im)/[^\s]+'
    shortener_matches = re.findall(shortener_pattern, converted_text, re.IGNORECASE)
    if shortener_matches:
        found_links.extend(shortener_matches)
        violations.append("URL shortener detected")
    
    # Method 5: Detect dot with spaces (e.g., "site . com")
    spaced_domain = r'[a-zA-Z0-9-]+\s*\.\s*(?:com|net|org|io|gg|xyz|info|co|me|tv|cc)'
    spaced_matches = re.findall(spaced_domain, converted_text, re.IGNORECASE)
    if spaced_matches:
        found_links.extend(spaced_matches)
        violations.append("Spaced domain detected")
    
    # Method 6: Detect "dot" written as text
    text_dot_pattern = r'[a-zA-Z0-9-]+\s*(?:dot|–¥0—Ç|d0t|d√∏t)\s*(?:com|net|org|io|gg|xyz)'
    text_dot_matches = re.findall(text_dot_pattern, converted_text, re.IGNORECASE)
    if text_dot_matches:
        found_links.extend(text_dot_matches)
        violations.append("Text 'dot' obfuscation detected")
    
    # Method 7: Detect IP addresses
    ip_pattern = r'\b(?:\d{1,3}\.){3}\d{1,3}\b'
    ip_matches = re.findall(ip_pattern, converted_text)
    if ip_matches:
        found_links.extend(ip_matches)
        violations.append("IP address detected")
    
    # Method 8: Check against blocked domains in BLOCKED_MESSAGES
    for blocked in BLOCKED_MESSAGES:
        if any(char in blocked for char in ['.', '/', ':']):  # It's a URL/domain
            # Check both original and converted text
            if blocked.lower() in converted_text or blocked.lower() in original_lower:
                violations.append(f"Blocked domain/URL: {blocked}")
                found_links.append(blocked)
    
    # Remove duplicates
    found_links = list(set(found_links))
    
    # Check if any found links are not in whitelist
    for link in found_links:
        link_lower = link.lower()
        is_allowed = False
        
        # Check if link contains any allowed domain
        for allowed_domain in ALLOWED_DOMAINS:
            if allowed_domain.lower() in link_lower:
                # Special check for github - only raw.githubusercontent with blocked path is blocked
                if "raw.githubusercontent.com" in link_lower:
                    # Check if it's in blocked messages
                    if any(blocked.lower() in link_lower for blocked in BLOCKED_MESSAGES):
                        violations.append(f"Blocked GitHub URL detected: {link[:50]}")
                    else:
                        is_allowed = True
                else:
                    is_allowed = True
                break
        
        if not is_allowed and link:
            violations.append(f"Unauthorized link detected: {link[:50]}")
    
    return len(violations) > 0, list(set(violations))

# === COMPREHENSIVE UNICODE DETECTION ===

def comprehensive_unicode_to_ascii(text):
    """Convert ALL Unicode variations to ASCII - COMPLETE A-Z MATHEMATICAL SYMBOLS"""
    if not text:
        return ""
    
    result = list(text)
    
    for i, char in enumerate(result):
        code = ord(char)
        
        # === MATHEMATICAL ALPHANUMERIC SYMBOLS - ALL COMPLETE A-Z RANGES ===
        
        # Mathematical Bold (ùêÄ-ùêô, ùêö-ùê≥) - COMPLETE A-Z
        if 0x1D400 <= code <= 0x1D419:  # ùêÄ-ùêô
            result[i] = chr(ord('A') + (code - 0x1D400))
        elif 0x1D41A <= code <= 0x1D433:  # ùêö-ùê≥
            result[i] = chr(ord('a') + (code - 0x1D41A))
        
        # Mathematical Italic (ùê¥-ùëç, ùëé-ùëß) - COMPLETE A-Z
        elif 0x1D434 <= code <= 0x1D44D:  # ùê¥-ùëç
            result[i] = chr(ord('A') + (code - 0x1D434))
        elif 0x1D44E <= code <= 0x1D467:  # ùëé-ùëß
            result[i] = chr(ord('a') + (code - 0x1D44E))
        
        # Mathematical Bold Italic (ùë®-ùíÅ, ùíÇ-ùíõ) - COMPLETE A-Z
        elif 0x1D468 <= code <= 0x1D481:  # ùë®-ùíÅ
            result[i] = chr(ord('A') + (code - 0x1D468))
        elif 0x1D482 <= code <= 0x1D49B:  # ùíÇ-ùíõ
            result[i] = chr(ord('a') + (code - 0x1D482))
        
        # Mathematical Script (ùíú-ùíµ, ùí∂-ùìè) - COMPLETE A-Z
        elif 0x1D49C <= code <= 0x1D4B5:  # ùíú-ùíµ
            result[i] = chr(ord('A') + (code - 0x1D49C))
        elif 0x1D4B6 <= code <= 0x1D4CF:  # ùí∂-ùìè
            result[i] = chr(ord('a') + (code - 0x1D4B6))
        
        # Mathematical Bold Script (ùìê-ùì©, ùì™-ùîÉ) - COMPLETE A-Z
        elif 0x1D4D0 <= code <= 0x1D4E9:  # ùìê-ùì©
            result[i] = chr(ord('A') + (code - 0x1D4D0))
        elif 0x1D4EA <= code <= 0x1D503:  # ùì™-ùîÉ
            result[i] = chr(ord('a') + (code - 0x1D4EA))
        
        # Mathematical Fraktur (ùîÑ-ùîú, ùîû-ùî∑) - COMPLETE A-Z
        elif 0x1D504 <= code <= 0x1D51D:  # ùîÑ-ùîú
            result[i] = chr(ord('A') + (code - 0x1D504))
        elif 0x1D51E <= code <= 0x1D537:  # ùîû-ùî∑
            result[i] = chr(ord('a') + (code - 0x1D51E))
        
        # Mathematical Double-Struck (ùî∏-‚Ñ§, ùïí-ùï´) - COMPLETE A-Z
        elif 0x1D538 <= code <= 0x1D551:  # ùî∏-‚Ñ§
            result[i] = chr(ord('A') + (code - 0x1D538))
        elif 0x1D552 <= code <= 0x1D56B:  # ùïí-ùï´
            result[i] = chr(ord('a') + (code - 0x1D552))
        
        # Mathematical Bold Fraktur (ùï¨-ùñÖ, ùñÜ-ùñü) - COMPLETE A-Z
        elif 0x1D56C <= code <= 0x1D585:  # ùï¨-ùñÖ
            result[i] = chr(ord('A') + (code - 0x1D56C))
        elif 0x1D586 <= code <= 0x1D59F:  # ùñÜ-ùñü
            result[i] = chr(ord('a') + (code - 0x1D586))
        
        # Mathematical Sans-Serif (ùñ†-ùñπ, ùñ∫-ùóì) - COMPLETE A-Z
        elif 0x1D5A0 <= code <= 0x1D5B9:  # ùñ†-ùñπ
            result[i] = chr(ord('A') + (code - 0x1D5A0))
        elif 0x1D5BA <= code <= 0x1D5D3:  # ùñ∫-ùóì
            result[i] = chr(ord('a') + (code - 0x1D5BA))
        
        # Mathematical Sans-Serif Bold (ùóî-ùó≠, ùóÆ-ùòá) - COMPLETE A-Z
        elif 0x1D5D4 <= code <= 0x1D5ED:  # ùóî-ùó≠
            result[i] = chr(ord('A') + (code - 0x1D5D4))
        elif 0x1D5EE <= code <= 0x1D607:  # ùóÆ-ùòá
            result[i] = chr(ord('a') + (code - 0x1D5EE))
        
        # Mathematical Sans-Serif Italic (ùòà-ùò°, ùò¢-ùòª) - COMPLETE A-Z
        elif 0x1D608 <= code <= 0x1D621:  # ùòà-ùò°
            result[i] = chr(ord('A') + (code - 0x1D608))
        elif 0x1D622 <= code <= 0x1D63B:  # ùò¢-ùòª
            result[i] = chr(ord('a') + (code - 0x1D622))
        
        # Mathematical Sans-Serif Bold Italic (ùòº-ùôï, ùôñ-ùôØ) - COMPLETE A-Z
        elif 0x1D63C <= code <= 0x1D655:  # ùòº-ùôï
            result[i] = chr(ord('A') + (code - 0x1D63C))
        elif 0x1D656 <= code <= 0x1D66F:  # ùôñ-ùôØ
            result[i] = chr(ord('a') + (code - 0x1D656))
        
        # Mathematical Monospace (ùô∞-ùöâ, ùöä-ùö£) - COMPLETE A-Z
        elif 0x1D670 <= code <= 0x1D689:  # ùô∞-ùöâ
            result[i] = chr(ord('A') + (code - 0x1D670))
        elif 0x1D68A <= code <= 0x1D6A3:  # ùöä-ùö£
            result[i] = chr(ord('a') + (code - 0x1D68A))
        
        # === ALL FLAG EMOJIS DETECTION ===
        # Regional Indicator Symbols (üá¶-üáø) - ALL FLAGS
        elif 0x1F1E6 <= code <= 0x1F1FF:  # üá¶-üáø (ALL COUNTRY FLAGS)
            result[i] = chr(ord('A') + (code - 0x1F1E6))
        
        # Mathematical digits - ALL VARIANTS
        elif 0x1D7CE <= code <= 0x1D7D7:  # Bold ùüé-ùüó
            result[i] = chr(ord('0') + (code - 0x1D7CE))
        elif 0x1D7D8 <= code <= 0x1D7E1:  # Double-struck ùüò-ùü°
            result[i] = chr(ord('0') + (code - 0x1D7D8))
        elif 0x1D7E2 <= code <= 0x1D7EB:  # Sans-serif ùü¢-ùü´
            result[i] = chr(ord('0') + (code - 0x1D7E2))
        elif 0x1D7EC <= code <= 0x1D7F5:  # Sans-serif bold ùü¨-ùüµ
            result[i] = chr(ord('0') + (code - 0x1D7EC))
        elif 0x1D7F6 <= code <= 0x1D7FF:  # Monospace ùü∂-ùüø
            result[i] = chr(ord('0') + (code - 0x1D7F6))
        
        # Fullwidth forms (Ôº°-Ôº∫, ÔΩÅ-ÔΩö, Ôºê-Ôºô)
        elif 0xFF21 <= code <= 0xFF3A:  # Ôº°-Ôº∫
            result[i] = chr(ord('A') + (code - 0xFF21))
        elif 0xFF41 <= code <= 0xFF5A:  # ÔΩÅ-ÔΩö
            result[i] = chr(ord('a') + (code - 0xFF41))
        elif 0xFF10 <= code <= 0xFF19:  # Ôºê-Ôºô
            result[i] = chr(ord('0') + (code - 0xFF10))
        
        # Enclosed Alphanumerics (‚í∂-‚ìè, ‚ìê-‚ì©)
        elif 0x24B6 <= code <= 0x24CF:  # ‚í∂-‚ìè
            result[i] = chr(ord('A') + (code - 0x24B6))
        elif 0x24D0 <= code <= 0x24E9:  # ‚ìê-‚ì©
            result[i] = chr(ord('a') + (code - 0x24D0))
        
        # Squared Latin Letters (üÑ∞-üÖâ, üÖ∞-üÜâ)
        elif 0x1F130 <= code <= 0x1F149:  # üÑ∞-üÖâ
            result[i] = chr(ord('A') + (code - 0x1F130))
        elif 0x1F170 <= code <= 0x1F189:  # üÖ∞-üÜâ
            result[i] = chr(ord('A') + (code - 0x1F170))
        
        # Box Drawing and Block Elements - convert to space
        elif 0x2500 <= code <= 0x257F or 0x2580 <= code <= 0x259F:
            result[i] = ' '
        
        # Cyrillic look-alikes - EXPANDED
        elif char in '–ê–í–°–ï–ù–Ü–ö–ú–û–†–¢–£–•–Ö–∞–µ–≤—Å—ñ–∫–º–æ—Ä—Å—Ç—É—Ö—ï':
            cyrillic_map = {
                '–ê':'A','–í':'B','–°':'C','–ï':'E','–ù':'H','–Ü':'I','–ö':'K','–ú':'M',
                '–û':'O','–†':'P','–¢':'T','–£':'Y','–•':'X','–Ö':'S',
                '–∞':'a','–µ':'e','–≤':'b','—Å':'c','—ñ':'i','–∫':'k','–º':'m',
                '–æ':'o','—Ä':'p','—Ç':'t','—É':'u','—Ö':'x','—ï':'s'
            }
            result[i] = cyrillic_map.get(char, char)
        
        # Greek look-alikes - EXPANDED
        elif char in 'ŒëŒíŒìŒîŒïŒñŒóŒòŒôŒöŒõŒúŒùŒûŒüŒ†Œ°Œ£Œ§Œ•Œ¶ŒßŒ®Œ©Œ±Œ≤Œ≥Œ¥ŒµŒ∂Œ∑Œ∏ŒπŒ∫ŒªŒºŒΩŒæŒøœÄœÅœÉœÑœÖœÜœáœàœâ':
            greek_map = {
                'Œë':'A','Œí':'B','Œì':'G','Œî':'D','Œï':'E','Œñ':'Z','Œó':'H','Œò':'T',
                'Œô':'I','Œö':'K','Œõ':'L','Œú':'M','Œù':'N','Œû':'X','Œü':'O','Œ†':'P',
                'Œ°':'P','Œ£':'S','Œ§':'T','Œ•':'Y','Œ¶':'F','Œß':'X','Œ®':'P','Œ©':'O',
                'Œ±':'a','Œ≤':'b','Œ≥':'g','Œ¥':'d','Œµ':'e','Œ∂':'z','Œ∑':'h','Œ∏':'t',
                'Œπ':'i','Œ∫':'k','Œª':'l','Œº':'m','ŒΩ':'n','Œæ':'x','Œø':'o','œÄ':'p',
                'œÅ':'r','œÉ':'s','œÑ':'t','œÖ':'u','œÜ':'f','œá':'x','œà':'p','œâ':'o'
            }
            result[i] = greek_map.get(char, char)
        
        # Additional Unicode ranges for symbols and special characters
        elif 0x2100 <= code <= 0x214F:  # Letterlike Symbols
            letterlike_map = {
                '‚ÑÄ':'a/c', '‚ÑÅ':'a/s', '‚ÑÇ':'C', '‚ÑÉ':'C', '‚ÑÑ':'CL', '‚ÑÖ':'c/o', '‚ÑÜ':'c/u',
                '‚Ñá':'E', '‚Ñà':'g', '‚Ñâ':'F', '‚Ñä':'g', '‚Ñã':'H', '‚Ñå':'H', '‚Ñç':'H',
                '‚Ñé':'h', '‚Ñè':'h', '‚Ñê':'I', '‚Ñë':'I', '‚Ñí':'L', '‚Ñì':'l', '‚Ñî':'lb',
                '‚Ñï':'N', '‚Ññ':'No', '‚Ñó':'P', '‚Ñò':'P', '‚Ñô':'P', '‚Ñö':'Q', '‚Ñõ':'R',
                '‚Ñú':'R', '‚Ñù':'R', '‚Ñû':'Rx', '‚Ñü':'R', '‚Ñ†':'SM', '‚Ñ°':'TEL', '‚Ñ¢':'TM',
                '‚Ñ£':'V', '‚Ñ§':'Z', '‚Ñ•':'oz', 'Œ©':'O', '‚Ñß':'O', '‚Ñ®':'Z', '‚Ñ©':'i',
                'K':'K', '√Ö':'A', '‚Ñ¨':'B', '‚Ñ≠':'C', '‚ÑØ':'e', '‚Ñ∞':'E', '‚Ñ±':'F',
                '‚Ñ≤':'F', '‚Ñ≥':'M', '‚Ñ¥':'o', '‚Ñµ':'N', '‚Ñ∂':'B', '‚Ñ∑':'G', '‚Ñ∏':'P',
                '‚Ñπ':'i', '‚Ñ∫':'Q', '‚Ñª':'FAX', '‚Ñº':'P', '‚ÑΩ':'G', '‚Ñæ':'P', '‚Ñø':'S',
                '‚ÖÄ':'S', '‚ÖÅ':'G', '‚ÖÇ':'L', '‚ÖÉ':'L', '‚ÖÑ':'Y', '‚ÖÖ':'D', '‚ÖÜ':'d',
                '‚Öá':'e', '‚Öà':'i', '‚Öâ':'j'
            }
            result[i] = letterlike_map.get(char, char)
        
        # Roman Numerals - ALL
        elif 0x2160 <= code <= 0x217F:
            roman_map = {
                '‚Ö†':'I', '‚Ö°':'II', '‚Ö¢':'III', '‚Ö£':'IV', '‚Ö§':'V', '‚Ö•':'VI',
                '‚Ö¶':'VII', '‚Öß':'VIII', '‚Ö®':'IX', '‚Ö©':'X', '‚Ö™':'XI', '‚Ö´':'XII',
                '‚Ö¨':'L', '‚Ö≠':'C', '‚ÖÆ':'D', '‚ÖØ':'M',
                '‚Ö∞':'i', '‚Ö±':'ii', '‚Ö≤':'iii', '‚Ö≥':'iv', '‚Ö¥':'v', '‚Öµ':'vi',
                '‚Ö∂':'vii', '‚Ö∑':'viii', '‚Ö∏':'ix', '‚Öπ':'x', '‚Ö∫':'xi', '‚Öª':'xii',
                '‚Öº':'l', '‚ÖΩ':'c', '‚Öæ':'d', '‚Öø':'m'
            }
            result[i] = roman_map.get(char, char)
        
        # Superscript and Subscript - ALL
        elif char in '‚Å∞¬π¬≤¬≥‚Å¥‚Åµ‚Å∂‚Å∑‚Å∏‚Åπ':
            super_map = {'‚Å∞':'0','¬π':'1','¬≤':'2','¬≥':'3','‚Å¥':'4','‚Åµ':'5','‚Å∂':'6','‚Å∑':'7','‚Å∏':'8','‚Åπ':'9'}
            result[i] = super_map.get(char, char)
        elif char in '‚ÇÄ‚ÇÅ‚ÇÇ‚ÇÉ‚ÇÑ‚ÇÖ‚ÇÜ‚Çá‚Çà‚Çâ':
            sub_map = {'‚ÇÄ':'0','‚ÇÅ':'1','‚ÇÇ':'2','‚ÇÉ':'3','‚ÇÑ':'4','‚ÇÖ':'5','‚ÇÜ':'6','‚Çá':'7','‚Çà':'8','‚Çâ':'9'}
            result[i] = sub_map.get(char, char)
        elif char in '·µÉ·µá·∂ú·µà·µâ·∂†·µç ∞‚Å± ≤·µèÀ°·µê‚Åø·µí·µñ ≥À¢·µó·µò·µõ ∑À£ ∏·∂ª·¥¨·¥Æ·¥∞·¥±·¥≥·¥¥·¥µ·¥∂·¥∑·¥∏·¥π·¥∫·¥º·¥æ·¥ø·µÄ·µÅ‚±Ω·µÇ':
            super_alpha_map = {
                '·µÉ':'a','·µá':'b','·∂ú':'c','·µà':'d','·µâ':'e','·∂†':'f','·µç':'g',' ∞':'h','‚Å±':'i',' ≤':'j',
                '·µè':'k','À°':'l','·µê':'m','‚Åø':'n','·µí':'o','·µñ':'p',' ≥':'r','À¢':'s','·µó':'t','·µò':'u',
                '·µõ':'v',' ∑':'w','À£':'x',' ∏':'y','·∂ª':'z','·¥¨':'A','·¥Æ':'B','·¥∞':'D','·¥±':'E',
                '·¥≥':'G','·¥¥':'H','·¥µ':'I','·¥∂':'J','·¥∑':'K','·¥∏':'L','·¥π':'M','·¥∫':'N','·¥º':'O',
                '·¥æ':'P','·¥ø':'R','·µÄ':'T','·µÅ':'U','‚±Ω':'V','·µÇ':'W'
            }
            result[i] = super_alpha_map.get(char, char)
        elif char in '‚Çê‚Çë‚Çï·µ¢‚±º‚Çñ‚Çó‚Çò‚Çô‚Çí‚Çö·µ£‚Çõ‚Çú·µ§·µ•‚Çì':
            sub_alpha_map = {
                '‚Çê':'a','‚Çë':'e','‚Çï':'h','·µ¢':'i','‚±º':'j','‚Çñ':'k','‚Çó':'l','‚Çò':'m','‚Çô':'n',
                '‚Çí':'o','‚Çö':'p','·µ£':'r','‚Çõ':'s','‚Çú':'t','·µ§':'u','·µ•':'v','‚Çì':'x'
            }
            result[i] = sub_alpha_map.get(char, char)
    
    return ''.join(result)

def detect_flag_emojis(text):
    """Detect ALL flag emoji patterns"""
    if not text:
        return False, []
    
    violations = []
    
    # Check for regional indicator symbols (flag emojis)
    flag_pattern = re.compile(r'[\U0001F1E6-\U0001F1FF]')
    flag_matches = flag_pattern.findall(text)
    
    if len(flag_matches) >= 2:  # Any flag combination
        # Convert flag emojis to letters
        flag_letters = []
        for flag_char in flag_matches:
            letter = chr(ord('A') + (ord(flag_char) - 0x1F1E6))
            flag_letters.append(letter)
        
        flag_sequence = ''.join(flag_letters)
        violations.append(f"Flag emoji pattern detected: {flag_sequence}")
    
    # Also check for single flag usage if it's excessive
    if len(flag_matches) >= 3:  # 3 or more flag emojis
        violations.append("Excessive flag emoji usage detected")
    
    return len(violations) > 0, violations

def advanced_ascii_art_extraction(text):
    """Enhanced ASCII art extraction with multiple detection methods"""
    if not text or len(text) < 5:
        return []
    
    extracted_sequences = []
    lines = text.split('\n')
    
    # Method 1: Vertical reading (column-by-column) - ENHANCED
    if len(lines) >= 2:
        max_length = max(len(line) for line in lines) if lines else 0
        for col in range(min(200, max_length)):  # Increased range
            vertical_chars = []
            for line in lines:
                if col < len(line):
                    char = line[col]
                    # Convert Unicode to ASCII first
                    converted_char = comprehensive_unicode_to_ascii(char)
                    if converted_char.isalpha():
                        vertical_chars.append(converted_char.lower())
            if len(vertical_chars) >= 2:  # Lowered threshold
                vertical_word = ''.join(vertical_chars)
                if len(vertical_word) >= 2:
                    extracted_sequences.append(vertical_word)
    
    # Method 2: Diagonal reading
    for start_row in range(len(lines)):
        for start_col in range(len(lines[start_row]) if start_row < len(lines) else 0):
            # Diagonal down-right
            diagonal_chars = []
            row, col = start_row, start_col
            while row < len(lines) and col < len(lines[row]):
                char = lines[row][col]
                converted_char = comprehensive_unicode_to_ascii(char)
                if converted_char.isalpha():
                    diagonal_chars.append(converted_char.lower())
                row += 1
                col += 1
            if len(diagonal_chars) >= 3:
                diagonal_word = ''.join(diagonal_chars)
                extracted_sequences.append(diagonal_word)
            
            # Diagonal down-left
            diagonal_chars = []
            row, col = start_row, start_col
            while row < len(lines) and col >= 0 and col < len(lines[row]):
                char = lines[row][col]
                converted_char = comprehensive_unicode_to_ascii(char)
                if converted_char.isalpha():
                    diagonal_chars.append(converted_char.lower())
                row += 1
                col -= 1
            if len(diagonal_chars) >= 3:
                diagonal_word = ''.join(diagonal_chars)
                extracted_sequences.append(diagonal_word)
    
    # Method 3: Horizontal reading with enhanced cleaning
    for line in lines:
        # Convert Unicode first
        converted_line = comprehensive_unicode_to_ascii(line)
        # Remove ASCII art characters but keep letters
        cleaned = re.sub(r'[|/\\()[\]{}#@*=_\-+<>~^`.:;\'"!?$%&0-9]', ' ', converted_line)
        words = cleaned.split()
        for word in words:
            if len(word) >= 2 and word.isalpha():  # Lowered threshold
                extracted_sequences.append(word.lower())
    
    # Method 4: Pattern-based extraction (looking for repeated structures)
    full_text = ' '.join(lines)
    converted_full = comprehensive_unicode_to_ascii(full_text)
    
    # Extract sequences of letters separated by non-letters
    letter_sequences = re.findall(r'[a-zA-Z]{2,}', converted_full)
    for seq in letter_sequences:
        extracted_sequences.append(seq.lower())
    
    # Method 5: Dense character block detection with Unicode conversion
    letters_only = re.sub(r'[^a-zA-Z]', '', converted_full).lower()
    if letters_only:
        # Extract overlapping substrings
        for i in range(len(letters_only) - 1):
            for length in range(2, min(15, len(letters_only) - i + 1)):
                chunk = letters_only[i:i+length]
                if len(chunk) >= 2:
                    extracted_sequences.append(chunk)
    
    # Method 6: Reverse reading
    for line in lines:
        converted_line = comprehensive_unicode_to_ascii(line)
        reversed_line = converted_line[::-1]
        cleaned = re.sub(r'[^a-zA-Z]', '', reversed_line).lower()
        if len(cleaned) >= 2:
            extracted_sequences.append(cleaned)
    
    return list(set(extracted_sequences))  # Remove duplicates

def detect_multi_line_art(text):
    """Enhanced multi-line ASCII art detection"""
    if not text or len(text) < 10:
        return False
    
    lines = text.split('\n')
    
    # Check for multiple lines
    if len(lines) > 4:
        return True
    
    # Check for consistent structure
    if len(lines) >= 2:
        lengths = [len(line) for line in lines if line.strip()]
        if lengths:
            avg_length = sum(lengths) / len(lengths)
            # Lower threshold for detection
            if avg_length > 15 and len([l for l in lengths if abs(l - avg_length) < 15]) >= 2:
                return True
    
    # Check for high density of special characters or Unicode
    for line in lines:
        if len(line) > 10:
            # Count special ASCII art characters
            special_count = sum(1 for c in line if c in '|/\\()[]{}#@*=_-+<>~^`.:;')
            # Count Unicode characters that could be used for art
            unicode_count = sum(1 for c in line if ord(c) > 127)
            
            total_special = special_count + unicode_count
            if total_special > len(line) * 0.2:  # Lowered threshold
                return True
    
    # Check for mathematical Unicode characters (common in bypasses)
    unicode_math_pattern = re.compile(r'[\U0001D400-\U0001D7FF]')  # Mathematical Alphanumeric Symbols
    if unicode_math_pattern.search(text):
        return True
    
    # Check for flag emojis or regional indicators
    flag_pattern = re.compile(r'[\U0001F1E6-\U0001F1FF]')
    if flag_pattern.search(text):
        return True
    
    return False

def is_whitelisted_word(word):
    """Check if word is whitelisted"""
    word_lower = word.lower()
    for whitelist_word in WHITELIST_WORDS:
        if word_lower == whitelist_word.lower():
            return True
    return False

def check_blocked_words_ultimate(text):
    """Ultimate blocked word detection with enhanced Unicode handling"""
    if not text:
        return False, []
    
    violations = []
    
    # Convert Unicode to ASCII first
    converted = comprehensive_unicode_to_ascii(text)
    
    # Normalize text (remove special characters, keep letters and spaces)
    normalized = re.sub(r'[^a-z0-9\s]', '', converted.lower())
    words = normalized.split()
    
    # Check individual words
    for word in words:
        if len(word) < 2 or is_whitelisted_word(word):
            continue
        
        for blocked in BLOCKED_WORDS:
            blocked_clean = re.sub(r'[^a-z]', '', blocked.lower())
            if len(blocked_clean) >= 2:
                # Exact match
                if word == blocked_clean:
                    violations.append(f"Blocked word: '{blocked}'")
                # Partial match with obfuscation
                elif blocked_clean in word and len(word) <= len(blocked_clean) + 4:  # Allow slight variations
                    if not is_whitelisted_word(word):
                        violations.append(f"Blocked word (obfuscated): '{blocked}' in '{word}'")
    
    # Check full text for hidden words
    full_letters = re.sub(r'[^a-z]', '', converted.lower())
    for blocked in BLOCKED_WORDS:
        blocked_clean = re.sub(r'[^a-z]', '', blocked.lower())
        if len(blocked_clean) >= 2 and blocked_clean in full_letters:
            # Check if it's not part of a whitelisted word
            is_in_whitelist = False
            for word in words:
                if is_whitelisted_word(word) and blocked_clean in word.lower():
                    is_in_whitelist = True
                    break
            
            if not is_in_whitelist:
                violations.append(f"Blocked word (hidden): '{blocked}'")
    
    # Enhanced ASCII art extraction
    if '\n' in text or len(text) > 30:  # Lowered threshold
        extracted_words = advanced_ascii_art_extraction(text)
        for extracted in extracted_words:
            if len(extracted) < 2:
                continue
            for blocked in BLOCKED_WORDS:
                blocked_clean = re.sub(r'[^a-z]', '', blocked.lower())
                if len(blocked_clean) >= 2:
                    if blocked_clean in extracted and not is_whitelisted_word(extracted):
                        violations.append(f"Blocked word (ASCII art): '{blocked}' detected in art pattern")
    
    # Check for leetspeak and number substitutions
    leetspeak_map = {'3': 'e', '1': 'i', '0': 'o', '4': 'a', '5': 's', '7': 't', '8': 'b'}
    leet_converted = converted.lower()
    for num, letter in leetspeak_map.items():
        leet_converted = leet_converted.replace(num, letter)
    
    leet_normalized = re.sub(r'[^a-z]', '', leet_converted)
    for blocked in BLOCKED_WORDS:
        blocked_clean = re.sub(r'[^a-z]', '', blocked.lower())
        if len(blocked_clean) >= 2 and blocked_clean in leet_normalized:
            violations.append(f"Blocked word (leetspeak): '{blocked}' detected")
    
    return len(violations) > 0, list(set(violations))

def detect_non_english(text):
    """STRICT non-English language detection - ONLY ENGLISH ALLOWED"""
    if not text or len(text.strip()) < 2:
        return False
    
    # Clean the text - remove URLs, mentions, channels, emojis
    cleaned_text = re.sub(r'http[s]?://\S+', '', text)
    cleaned_text = re.sub(r'<@[!&]?\d+>', '', cleaned_text)
    cleaned_text = re.sub(r'<#\d+>', '', cleaned_text)
    cleaned_text = re.sub(r'<:\w+:\d+>', '', cleaned_text)
    
    # Remove emojis
    try:
        cleaned_text = emoji.demojize(cleaned_text)
        cleaned_text = re.sub(r':[a-z_]+:', '', cleaned_text)
    except:
        pass
    
    # Convert Unicode to ASCII first to handle fancy fonts
    cleaned_text = comprehensive_unicode_to_ascii(cleaned_text)
    
    # Remove numbers, punctuation, and special characters - keep only letters and spaces
    text_only = re.sub(r'[^a-zA-Z\s]', '', cleaned_text)
    text_only = text_only.strip()
    
    # If no letters remain after cleaning, allow it (could be just numbers/symbols)
    if len(text_only) < 2:
        return False
    
    # Check for non-English characters that survived the Unicode conversion
    # Chinese/Japanese/Korean characters
    if re.search(r'[\u4e00-\u9fff\u3040-\u309f\u30a0-\u30ff\uac00-\ud7af]', text):
        return True
    
    # Arabic/Hebrew characters
    if re.search(r'[\u0600-\u06ff\u0590-\u05ff]', text):
        return True
    
    # Cyrillic characters (that weren't converted)
    if re.search(r'[\u0400-\u04ff]', text):
        return True
    
    # Thai, Hindi, and other Asian scripts
    if re.search(r'[\u0e00-\u0e7f\u0900-\u097f\u1000-\u109f]', text):
        return True
    
    # Check if the text contains mostly English letters
    total_chars = len(text_only.replace(' ', ''))
    if total_chars == 0:
        return False
    
    english_chars = len(re.findall(r'[a-zA-Z]', text_only))
    english_ratio = english_chars / total_chars
    
    # STRICT: If less than 90% English characters, consider it non-English
    if english_ratio < 0.9:
        return True
    
    # Additional check: Look for common non-English patterns
    # Check for sequences that look like other languages
    words = text_only.lower().split()
    suspicious_patterns = [
        # Common Chinese pinyin patterns
        r'^[bcdfghjklmnpqrstvwxyz]{3,}$',  # Too many consonants
        # Common patterns in other languages
        r'[qxz]{2,}',  # Repeated uncommon letters
        r'^[aeiou]{4,}$',  # Too many vowels in sequence
    ]
    
    for word in words:
        if len(word) > 2:
            for pattern in suspicious_patterns:
                if re.search(pattern, word):
                    # Only flag if it's a longer word and doesn't look like English
                    if len(word) > 4 and not any(common in word for common in ['the', 'and', 'you', 'that', 'was', 'for', 'are', 'with', 'his', 'they']):
                        return True
    
    return False

def analyze_message_content(content):
    """Enhanced message analysis with all detection methods"""
    if not content or len(content) < 1:
        return False, []
    
    violations = []
    
    # Check for multi-line ASCII art
    if detect_multi_line_art(content):
        violations.append("Multi-line ASCII art detected (likely bypass attempt)")
    
    # Check for ALL flag emojis
    has_flags, flag_violations = detect_flag_emojis(content)
    violations.extend(flag_violations)
    
    # Check for blocked words with enhanced detection
    has_blocked, blocked_violations = check_blocked_words_ultimate(content)
    violations.extend(blocked_violations)
    
    # Check for ENHANCED link detection
    has_links, link_violations = detect_links(content)
    violations.extend(link_violations)
    
    # Check for excessive formatting (potential bypass)
    markdown_chars = content.count('*') + content.count('_') + content.count('~') + content.count('|') + content.count('`')
    if len(content) > 5 and markdown_chars > len(content) * 0.4:  # Lowered threshold
        violations.append("Excessive formatting (possible bypass)")
    
    # Check for suspicious Unicode patterns - COMPLETE MATHEMATICAL SYMBOLS
    unicode_math_count = len(re.findall(r'[\U0001D400-\U0001D7FF]', content))
    if unicode_math_count > 2:
        violations.append("Mathematical Unicode symbols detected (bypass attempt)")
    
    # Check for mixed scripts (potential obfuscation)
    scripts = []
    if re.search(r'[a-zA-Z]', content): scripts.append('latin')
    if re.search(r'[\u0400-\u04FF]', content): scripts.append('cyrillic')
    if re.search(r'[\u0370-\u03FF]', content): scripts.append('greek')
    if re.search(r'[\U0001D400-\U0001D7FF]', content): scripts.append('math')
    if re.search(r'[\U0001F1E6-\U0001F1FF]', content): scripts.append('flags')
    
    if len(scripts) > 2:
        violations.append("Mixed scripts detected (potential obfuscation)")
    
    return len(violations) > 0, violations

def check_auto_reply(message_content):
    """Check if message matches auto-reply pattern"""
    if not message_content or len(message_content.strip()) < 3:
        return None
    
    cleaned_content = message_content.strip()
    for pattern, reply_data in AUTO_REPLY_PATTERNS.items():
        if re.search(pattern, cleaned_content):
            return reply_data['response']
    return None

# === MESSAGE PROCESSING ===

async def process_message(message, is_edit=False):
    """Enhanced message processing - SILENT DELETE ONLY - NO DMs, NO WARNINGS"""
    if message.author.bot or not message.guild:
        return
    
    if message.channel.id not in MONITORED_CHANNELS:
        await bot.process_commands(message)
        return
    
    guild_member = message.guild.get_member(message.author.id)
    if not guild_member:
        return
    
    # Check auto-reply first (works for everyone including bypass roles)
    auto_reply = check_auto_reply(message.content)
    if auto_reply:
        try:
            await message.reply(auto_reply)
        except:
            pass
    
    # If user has bypass role, skip moderation
    if any(role.id in BYPASS_ROLES for role in guild_member.roles):
        return
    
    # Check STRICT non-English - ONLY ENGLISH ALLOWED
    if detect_non_english(message.content):
        try:
            await message.delete()
        except discord.Forbidden:
            pass
        
        # Log non-English detection
        log_channel = bot.get_channel(LOG_CHANNEL_ID)
        if log_channel:
            embed = discord.Embed(
                title="üåê Non-English Message Blocked",
                description=f"**User:** {guild_member.mention}\n**Channel:** {message.channel.mention}",
                color=0x3498db,
                timestamp=datetime.datetime.now(datetime.timezone.utc)
            )
            embed.add_field(name="Reason", value="Only English is allowed in this server", inline=False)
            embed.add_field(name="Original Message", value=f"```\n{message.content[:300]}\n```", inline=False)
            
            # Show Unicode conversion
            converted = comprehensive_unicode_to_ascii(message.content)
            if converted != message.content:
                embed.add_field(name="Unicode ‚Üí ASCII", value=f"```\n{converted[:200]}\n```", inline=False)
            
            try:
                await log_channel.send(embed=embed)
            except:
                pass
        
        # NO CHANNEL WARNINGS OR DM - SILENT DELETE ONLY
        return
    
    # Analyze content for violations
    is_violation, violation_reasons = analyze_message_content(message.content)
    
    if is_violation:
        try:
            await message.delete()
        except discord.Forbidden:
            pass
        
        # Log violation
        log_channel = bot.get_channel(LOG_CHANNEL_ID)
        if log_channel:
            violation_text = '\n'.join(f"‚Ä¢ {reason}" for reason in violation_reasons[:10])  # Show more violations
            
            display_content = message.content
            if len(display_content) > 500:
                display_content = display_content[:497] + "..."
            
            title = "üö´ Message Blocked" if not is_edit else "üö´ Edited Message Blocked"
            embed = discord.Embed(
                title=title,
                description=f"**User:** {guild_member.mention}\n**Channel:** {message.channel.mention}",
                color=0xff4444,
                timestamp=datetime.datetime.now(datetime.timezone.utc)
            )
            embed.add_field(name="Violations", value=violation_text, inline=False)
            embed.add_field(name="Original Message", value=f"```\n{display_content}\n```", inline=False)
            
            # Show Unicode conversion
            converted = comprehensive_unicode_to_ascii(message.content)
            if converted != message.content and len(converted) < 400:
                embed.add_field(name="Unicode ‚Üí ASCII", value=f"```\n{converted[:300]}\n```", inline=False)
            
            # Show ASCII art extraction if detected
            if detect_multi_line_art(message.content):
                extracted = advanced_ascii_art_extraction(message.content)
                if extracted:
                    extracted_preview = ', '.join(extracted[:15])  # Show more extractions
                    if len(extracted_preview) > 200:
                        extracted_preview = extracted_preview[:197] + "..."
                    embed.add_field(name="Extracted from Art", value=f"`{extracted_preview}`", inline=False)
            
            try:
                await log_channel.send(embed=embed)
            except Exception as e:
                print(f"Error sending to log: {e}")
        
        # NO CHANNEL WARNINGS OR DM - SILENT DELETE ONLY
        
        return
    
    await bot.process_commands(message)

# === ENHANCED CHANNEL SCANNER ===

@tasks.loop(count=1)
async def scan_channels_on_startup():
    """Enhanced channel scan with better detection"""
    await bot.wait_until_ready()
    print("üîç Starting COMPLETE channel scan for existing messages...")
    
    deleted_count = 0
    scanned_count = 0
    
    for channel_id in MONITORED_CHANNELS:
        try:
            channel = bot.get_channel(channel_id)
            if not channel:
                continue
            
            print(f"   Scanning #{channel.name}...")
            
            async for message in channel.history(limit=200):  # Increased scan limit
                scanned_count += 1
                if message.author.bot:
                    continue
                
                guild_member = message.guild.get_member(message.author.id)
                if not guild_member:
                    continue
                
                if any(role.id in BYPASS_ROLES for role in guild_member.roles):
                    continue
                
                # Check violations with enhanced detection
                is_violation, violation_reasons = analyze_message_content(message.content)
                is_non_english = detect_non_english(message.content)
                
                if is_violation or is_non_english:
                    try:
                        await message.delete()
                        deleted_count += 1
                        print(f"   ‚úì Deleted message from {message.author.name}: {violation_reasons[:2] if is_violation else ['Non-English']}")
                        await asyncio.sleep(0.5)  # Rate limit protection
                    except:
                        pass
        except Exception as e:
            print(f"Error scanning channel {channel_id}: {e}")
    
    print(f"‚úÖ COMPLETE scan finished! Scanned {scanned_count} messages, deleted {deleted_count} violations.")

# === HEALTH CHECK SERVER ===

async def health_check_server():
    """Enhanced health check server for Render"""
    async def health(request):
        return web.Response(text="‚úÖ COMPLETE Discord Filter Bot is running!\nüõ°Ô∏è ENHANCED Link Detection Active\nüîó URL Shortener Detection Active\nüåê Domain Obfuscation Detection Active\nüõ°Ô∏è ALL Mathematical Unicode A-Z Detection Active\nüö® ALL Flag Emoji Detection Active\nüåê STRICT English-Only Language Detection\n‚ùå NO User DMs\n‚ùå NO Channel Warnings")
    
    async def stats(request):
        stats_text = f"""üìä COMPLETE Bot Statistics:
Monitored Channels: {len(MONITORED_CHANNELS)}
Blocked Words: {len(BLOCKED_WORDS)}
Allowed Domains: {len(ALLOWED_DOMAINS)}
Auto-Reply Patterns: {len(AUTO_REPLY_PATTERNS)}
Servers: {len(bot.guilds) if bot.guilds else 0}
Status: üü¢ COMPLETE Active
Features: ENHANCED Link Detection + ALL A-Z Mathematical Unicode + ALL Flag Emojis + STRICT English-Only
User Notifications: ‚ùå SILENT DELETE ONLY"""
        return web.Response(text=stats_text)
    
    app = web.Application()
    app.router.add_get('/', health)
    app.router.add_get('/health', health)
    app.router.add_get('/stats', stats)
    
    runner = web.AppRunner(app)
    await runner.setup()
    port = int(os.getenv('PORT', 10000))
    site = web.TCPSite(runner, '0.0.0.0', port)
    await site.start()
    print(f"üåê COMPLETE health server running on port {port}")

# === EVENTS ===

@bot.event
async def on_ready():
    print(f'‚úÖ {bot.user} is online with COMPLETE detection!')
    print(f'üì¢ Monitoring channels: {MONITORED_CHANNELS}')
    print(f'üõ°Ô∏è COMPLETE ASCII art detection: ENABLED')
    print(f'üîó ENHANCED link detection: ENABLED')
    print(f'‚ùå User DMs: DISABLED')
    print(f'‚ùå Channel warnings: DISABLED')
    print(f'üåê STRICT English-only detection: ENABLED')
    print(f'üîç Scanning for: {len(BLOCKED_WORDS)} blocked words')
    print(f'ü§ñ Auto-reply patterns: {len(AUTO_REPLY_PATTERNS)} active')
    print(f'üåç COMPLETE Unicode support: ALL A-Z Mathematical symbols')
    print(f'üéØ ALL Flag emoji detection: ENABLED (üá¶-üáø)')
    print(f'üî§ Mathematical symbols detection: ALL VARIANTS A-Z')
    print(f'üìù Example detection: ùî∏‚ÑïùïãùïÄ ùïÇùîΩ‚ÑÇ ùîªùïÜùîæ ‚Üí ANTI KFC DOG')
    print(f'üö´ Chinese/Non-English: STRICT BLOCKING')
    print(f'üîó Link detection: URL shorteners, obfuscation, IP addresses')
    
    # Start health server
    bot.loop.create_task(health_check_server())
    
    # Start enhanced channel scanner
    scan_channels_on_startup.start()

@bot.event
async def on_message(message):
    await process_message(message, is_edit=False)

@bot.event
async def on_message_edit(before, after):
    await process_message(after, is_edit=True)

# === ENHANCED ADMIN COMMANDS ===

@bot.command(name="addchannel")
@commands.has_permissions(administrator=True)
async def add_channel(ctx, channel: discord.TextChannel):
    if channel.id in MONITORED_CHANNELS:
        await ctx.send(f"‚ö†Ô∏è {channel.mention} already monitored.", delete_after=10)
    else:
        MONITORED_CHANNELS.append(channel.id)
        await ctx.send(f"‚úÖ Now monitoring {channel.mention} with COMPLETE detection", delete_after=10)

@bot.command(name="removechannel")
@commands.has_permissions(administrator=True)
async def remove_channel(ctx, channel: discord.TextChannel):
    if channel.id in MONITORED_CHANNELS:
        MONITORED_CHANNELS.remove(channel.id)
        await ctx.send(f"‚úÖ Stopped monitoring {channel.mention}", delete_after=10)
    else:
        await ctx.send(f"‚ö†Ô∏è {channel.mention} not monitored.", delete_after=10)

@bot.command(name="listchannels")
@commands.has_permissions(administrator=True)
async def list_channels(ctx):
    if MONITORED_CHANNELS:
        channels = [f"<#{ch_id}>" for ch in MONITORED_CHANNELS]
        await ctx.send(f"üì¢ **COMPLETE Monitored Channels:**\n" + "\n".join(channels), delete_after=30)
    else:
        await ctx.send("‚ö†Ô∏è No channels monitored.", delete_after=10)

@bot.command(name="rescan")
@commands.has_permissions(administrator=True)
async def rescan_channels(ctx):
    """Manually trigger a COMPLETE channel rescan"""
    await ctx.send("üîç Starting COMPLETE channel rescan...", delete_after=5)
    
    deleted_count = 0
    scanned_count = 0
    
    for channel_id in MONITORED_CHANNELS:
        try:
            channel = bot.get_channel(channel_id)
            if not channel:
                continue
            
            async for message in channel.history(limit=200):
                scanned_count += 1
                if message.author.bot:
                    continue
                
                guild_member = message.guild.get_member(message.author.id)
                if not guild_member or any(role.id in BYPASS_ROLES for role in guild_member.roles):
                    continue
                
                is_violation, _ = analyze_message_content(message.content)
                is_non_english = detect_non_english(message.content)
                
                if is_violation or is_non_english:
                    try:
                        await message.delete()
                        deleted_count += 1
                        await asyncio.sleep(0.5)
                    except:
                        pass
        except:
            pass
    
    await ctx.send(f"‚úÖ COMPLETE rescan finished! Scanned {scanned_count} messages, deleted {deleted_count}.", delete_after=15)

@bot.command(name="testmessage")
@commands.has_permissions(administrator=True)
async def test_message(ctx, *, text: str):
    """Test message with COMPLETE detection"""
    is_violation, violations = analyze_message_content(text)
    has_flags, flag_violations = detect_flag_emojis(text)
    is_non_english = detect_non_english(text)
    has_links, link_violations = detect_links(text)
    
    embed = discord.Embed(
        title="üîç COMPLETE Scanner Test",
        color=0xff4444 if (is_violation or has_flags or is_non_english or has_links) else 0x44ff44
    )
    
    if is_violation or has_flags or is_non_english or has_links:
        embed.add_field(name="üö´ BLOCKED", value="Message would be deleted", inline=False)
        all_violations = violations + flag_violations + link_violations
        if is_non_english:
            all_violations.append("Non-English language detected")
        embed.add_field(name="Violations", value='\n'.join(f"‚Ä¢ {v}" for v in all_violations[:10]), inline=False)
    else:
        embed.add_field(name="‚úÖ ALLOWED", value="Message would pass all COMPLETE checks", inline=False)
    
    embed.add_field(name="Original", value=f"```{text[:200]}```", inline=False)
    
    # Show Unicode conversion
    converted = comprehensive_unicode_to_ascii(text)
    if converted != text:
        embed.add_field(name="Unicode ‚Üí ASCII (COMPLETE)", value=f"```{converted[:200]}```", inline=False)
    
    # Show ASCII art extraction
    if detect_multi_line_art(text):
        extracted = advanced_ascii_art_extraction(text)
        if extracted:
            embed.add_field(name="ASCII Art Extraction", value=f"`{', '.join(extracted[:10])}`", inline=False)
    
    # Show detection details
    details = []
    if re.search(r'[\U0001D400-\U0001D7FF]', text):
        details.append("Mathematical Unicode detected (ALL A-Z variants)")
    if re.search(r'[\U0001F1E6-\U0001F1FF]', text):
        details.append("Flag emojis detected (ALL country flags)")
    if is_non_english:
        details.append("Non-English language detected (STRICT)")
    if has_links:
        details.append("ENHANCED link detection triggered")
    
    if details:
        embed.add_field(name="COMPLETE Detection Details", value='\n'.join(f"‚Ä¢ {d}" for d in details), inline=False)
    
    await ctx.send(embed=embed, delete_after=90)

@bot.command(name="filterhelp")
@commands.has_permissions(administrator=True)
async def filter_help(ctx):
    """Show all COMPLETE commands"""
    embed = discord.Embed(
        title="üõ°Ô∏è COMPLETE Filter Bot Commands",
        description="Advanced bypass detection with ENHANCED link detection + COMPLETE A-Z Unicode + ALL flags + STRICT English-only",
        color=0x3498db
    )
    
    embed.add_field(
        name="üì¢ Channel Management",
        value="`$addchannel #channel` - Monitor channel\n"
              "`$removechannel #channel` - Stop monitoring\n"
              "`$listchannels` - Show monitored channels\n"
              "`$rescan` - COMPLETE scan for violations",
        inline=False
    )
    
    embed.add_field(
        name="üîç Testing & Moderation",
        value="`$testmessage <text>` - Full COMPLETE test\n"
              "`$stats` - Show COMPLETE statistics",
        inline=False
    )
    
    embed.add_field(
        name="üéØ COMPLETE Features",
        value="‚úÖ Auto-scans on startup (200 msgs/channel)\n"
              "‚úÖ ENHANCED link detection (8+ methods)\n"
              "‚úÖ URL shortener detection\n"
              "‚úÖ Domain obfuscation detection\n"
              "‚úÖ IP address detection\n"
              "‚ùå User DMs DISABLED\n"
              "‚ùå Channel warnings DISABLED\n"
              "‚úÖ ALL Mathematical Unicode A-Z detection\n"
              "‚úÖ ALL Flag emoji detection (üá¶-üáø)\n"
              "‚úÖ STRICT English-only language detection\n"
              "‚úÖ Enhanced ASCII art extraction\n"
              "‚úÖ Diagonal & reverse reading\n"
              "‚úÖ Mixed script detection\n"
              "‚úÖ Leetspeak detection\n"
              "‚úÖ Example: ùî∏‚ÑïùïãùïÄ ùïÇùîΩ‚ÑÇ ùîªùïÜùîæ ‚Üí DETECTED\n"
              "‚úÖ Chinese/Non-English ‚Üí BLOCKED\n"
              "‚úÖ Unauthorized links ‚Üí BLOCKED",
        inline=False
    )
    
    await ctx.send(embed=embed, delete_after=120)

@bot.command(name="stats")
@commands.has_permissions(administrator=True)
async def show_stats(ctx):
    """Show COMPLETE bot statistics"""
    embed = discord.Embed(
        title="üìä COMPLETE Filter Bot Statistics",
        color=0x2ecc71
    )
    
    embed.add_field(name="Monitored Channels", value=str(len(MONITORED_CHANNELS)), inline=True)
    embed.add_field(name="Blocked Words", value=str(len(BLOCKED_WORDS)), inline=True)
    embed.add_field(name="Allowed Domains", value=str(len(ALLOWED_DOMAINS)), inline=True)
    embed.add_field(name="Auto-Reply Patterns", value=str(len(AUTO_REPLY_PATTERNS)), inline=True)
    embed.add_field(name="Servers", value=str(len(bot.guilds)), inline=True)
    embed.add_field(name="User Notifications", value="‚ùå SILENT", inline=True)
    embed.add_field(name="Status", value="üü¢ COMPLETE Active", inline=True)
    
    embed.add_field(
        name="COMPLETE Detection Capabilities",
        value="‚Ä¢ ENHANCED link detection (8+ methods)\n"
              "‚Ä¢ URL shortener detection\n"
              "‚Ä¢ Domain obfuscation detection\n"
              "‚Ä¢ IP address detection\n"
              "‚Ä¢ ALL Mathematical Unicode A-Z mappings\n"
              "‚Ä¢ ALL Flag emoji detection (üá¶-üáø)\n"
              "‚Ä¢ STRICT English-only language detection\n"
              "‚Ä¢ Multi-directional ASCII art reading\n"
              "‚Ä¢ Mixed script analysis\n"
              "‚Ä¢ Leetspeak conversion\n"
              "‚Ä¢ Example: ùî∏‚ÑïùïãùïÄ ùïÇùîΩ‚ÑÇ ùîªùïÜùîæ ‚Üí ANTI KFC DOG\n"
              "‚Ä¢ Chinese text ‚Üí BLOCKED IMMEDIATELY\n"
              "‚Ä¢ Unauthorized links ‚Üí BLOCKED SILENTLY",
        inline=False
    )
    
    await ctx.send(embed=embed, delete_after=60)

# === ERROR HANDLING ===

@bot.event
async def on_command_error(ctx, error):
    if isinstance(error, commands.MissingPermissions):
        await ctx.send("‚ùå You don't have permission to use this command.", delete_after=10)
    elif isinstance(error, commands.MissingRequiredArgument):
        await ctx.send("‚ùå Missing required argument. Use `$filterhelp` for command list.", delete_after=10)
    elif isinstance(error, commands.BadArgument):
        await ctx.send("‚ùå Invalid argument. Use `$filterhelp` for command list.", delete_after=10)
    else:
        print(f"Command error: {error}")

# === START BOT ===

if __name__ == "__main__":
    load_dotenv()
    token = os.getenv("DISCORD_TOKEN") or os.getenv("TOKEN")
    
    if not token:
        print("‚ùå Bot token not found! Set DISCORD_TOKEN or TOKEN in your .env file.")
        exit(1)
    
    print("üöÄ Starting COMPLETE Discord Filter Bot...")
    print("üõ°Ô∏è COMPLETE Unicode Detection System Loading...")
    print("üîó ENHANCED Link Detection System Loading...")
    print("‚ùå User DM System DISABLED...")
    print("‚ùå Channel Warning System DISABLED...")
    print("üåê STRICT English-Only Detection Loading...")
    print("üéØ ALL Flag Emoji Detection Loading...")
    print("üî§ ALL Mathematical A-Z Symbols Loading...")
    try:
        bot.run(token)
    except discord.LoginFailure:
        print("‚ùå Invalid bot token!")
    except Exception as e:
        print(f"‚ùå Failed to start bot: {e}")
